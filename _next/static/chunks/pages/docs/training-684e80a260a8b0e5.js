(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[237],{4870:function(e,t,n){(window.__NEXT_P=window.__NEXT_P||[]).push(["/docs/training",function(){return n(1913)}])},8177:function(e,t,n){"use strict";var i=n(5893);t.Z={logo:(0,i.jsx)("svg",{xmlns:"http://www.w3.org/2000/svg",width:"130",height:"30.555",viewBox:"0 0 130 30.555",children:(0,i.jsx)("g",{id:"Group_1","data-name":"Group 1",transform:"translate(-121.7 -308.1)",children:(0,i.jsx)("path",{id:"Union_1","data-name":"Union 1",d:"M95.7,15.435C95.7,6.4,102.979,0,113.224,0c8.6,0,15.028,4.124,16.776,10.722l-9.673,2c-.785-3.3-3.213-5.067-7.1-5.067-4.711,0-7.6,2.946-7.6,7.619,0,4.713,2.855,7.58,7.638,7.58,3.855,0,6.389-1.767,7.068-5.066l9.6,2.357c-2.106,6.6-8.353,10.408-17.026,10.408C102.408,30.555,95.7,24.664,95.7,15.435ZM73.959,29.613,61.5.982H71.889l6.818,17.6a13.878,13.878,0,0,1,.856,3.064h.143a19.312,19.312,0,0,1,.857-3.064L87.381.982H97.768L85.31,29.613Zm-43.3,0V13.9a41.259,41.259,0,0,1,.5-6.048h-.179c-.214,1.021-1.071,3.77-1.749,5.695l-5.64,16.063H14.885L9.566,13.628c-.714-2.239-1.321-4.4-1.642-5.773H7.781A37.945,37.945,0,0,1,8.138,13.9v15.71H0V.982H13.885l4.64,14.531a16.675,16.675,0,0,1,.964,3.574h.072a21.442,21.442,0,0,1,.964-3.653L24.986.982H39.228V29.613Zm11.458-.039V.982h9.388v20.7H67.891v7.894Z",transform:"translate(121.7 308.1)",fill:"#fff"})})}),project:{link:"https://github.com/mlVibeCaptions"},footer:{text:"MLVC 2023 - This website is an online documentation of Antonis kalagkatsis' MSc thesis in the National and Kapodistrian University of Athens, Department of Communication and Media Studies, Digital Communication Media and Interaction Environments"},primaryHue:189,feedback:{content:null},editLink:{text:null},sidebar:{defaultMenuCollapseLevel:1},useNextSeoProps:()=>({titleTemplate:"%s â€¢ MLVC"})}},1913:function(e,t,n){"use strict";n.r(t),n.d(t,{default:function(){return l.Z}});var i=n(5893),a=n(4526),r=n(7928),o=n(8177);n(5513);var s=n(1151),d=n(5675),c=n.n(d),p={src:"/_next/static/media/data-split.a82c2e2e.png",height:1110,width:1670,blurDataURL:"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAgAAAAFCAYAAAB4ka1VAAAAcUlEQVR42mMAgY0XzzKD6Fu3b9sAsR2I/WDnTpAYKnhy917IvRs3I1AE+Tcv52DYu0HR9uBWFYYdq5UZNq9QqujqU3uWka76KTKMk0Fm6ypRqUNbU9UOb093OrozT+nA1tTIuub4V5kZuV+yM5QYCAEAzVossJtOnEgAAAAASUVORK5CYII=",blurWidth:8,blurHeight:5},l=n(6092);function m(e){let t=Object.assign({h1:"h1",p:"p",h2:"h2"},(0,s.ah)(),e.components);return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(t.h1,{children:"Training"}),"\n",(0,i.jsx)(t.p,{children:"In the previous section I presented the implementation and configuration of the CNN architectural approaches used in this research to create an ACLF. Now, in this section I detail the training and evaluation phase of the DL model and by extension the CNN."}),"\n",(0,i.jsx)(t.h2,{id:"training-implementation",children:"Training Implementation"}),"\n",(0,i.jsx)(t.p,{children:"In this section I present the implementation of the training class of the DL model. The fundamental method for conducting the training process is the training loop. This method defines how many times all samples in the dataset will be passed through the CNN model, i.e. it defines the number of iterations. Each complete iteration, in which all samples have passed through the model is called an epoch (epoch ). Because in ACLF problems usually as in this research we have to manage datasets with very large volume, the input of samples into the CNN is done in batches (batch ). The size of the batch is a numerical value and is controlled through the super parameters of the DL model."}),"\n",(0,i.jsx)(t.h2,{id:"data-split",children:"Data Split"}),"\n",(0,i.jsx)(c(),{src:p,width:900,height:400})]})}e=n.hmd(e),(0,a.j)({pageNextRoute:"/docs/training",pageOpts:{filePath:"pages/docs/training.mdx",route:"/docs/training",frontMatter:{},pageMap:[{kind:"Meta",data:{index:{title:"Home",type:"page",display:"hidden",theme:{typesetting:"article",layout:"full",breadcrumb:!0,footer:!0,sidebar:!1,toc:!0,pagination:!1}},docs:{title:"Research",type:"page"},dataset:{title:"Dataset",type:"page",theme:{typesetting:"article",layout:"default",breadcrumb:!0,footer:!0,sidebar:!0,toc:!0,pagination:!0}},experiments:{title:"Experiments",type:"page"},technology:{title:"Technology",type:"menu",items:{pytorch:{title:"Pytorch",href:"https://pytorch.org/",newWindow:!0},torchaudio:{title:"torch audio",href:"https://pytorch.org/audio/stable/index.html",newWindow:!0}}}}},{kind:"MdxPage",name:"dataset",route:"/dataset"},{kind:"Folder",name:"docs",route:"/docs",children:[{kind:"Meta",data:{abstract:{title:"Abstract",theme:{typesetting:"article",layout:"full"}},"Research Objectives":{type:"separator",title:"Research Objectives"},"problem-definition":"Problem definition",limitations:"Limitations","Project Architecture":{type:"separator",title:"Project Architecture"},"dl-pipeline":"DL Pipeline","technology-stack":"Technology Stack","Collecting data":{type:"separator",title:"Data Collection"},scraping:"Scraping",dataset:"Dataset","Exploratory analysis":{type:"separator",title:"Exploratory data analysis"},"data-exploration":"Audio Analysis","feature-extraction":"Feature Extraction","pre-processing":"Pre-processing",convolutional_network:{type:"separator",title:"Model"},cnn:"Convolutional Neural Network (CNN)",architecture:"Architecture",training:"Training",performance:"Performance",Conclusion:{type:"separator",title:"Conclusions"},contribution:"Contribution",discussion:"Discussion",endnotes:{type:"separator",title:"Endnotes"},sources:"Sources",references:"References","audio-datasets":"Audio Datasets"}},{kind:"MdxPage",name:"abstract",route:"/docs/abstract"},{kind:"MdxPage",name:"architecture",route:"/docs/architecture"},{kind:"MdxPage",name:"audio-datasets",route:"/docs/audio-datasets"},{kind:"MdxPage",name:"cnn",route:"/docs/cnn"},{kind:"MdxPage",name:"contribution",route:"/docs/contribution"},{kind:"MdxPage",name:"data-exploration",route:"/docs/data-exploration"},{kind:"Folder",name:"dataset",route:"/docs/dataset",children:[{kind:"Meta",data:{"design-principles":"Design Principles",taxonomy:"Taxonomy Construction","descriptive-statistics":"Descriptive Statistics"}},{kind:"MdxPage",name:"descriptive-statistics",route:"/docs/dataset/descriptive-statistics"},{kind:"MdxPage",name:"design-principles",route:"/docs/dataset/design-principles"},{kind:"MdxPage",name:"taxonomy",route:"/docs/dataset/taxonomy"}]},{kind:"MdxPage",name:"discussion",route:"/docs/discussion"},{kind:"MdxPage",name:"dl-pipeline",route:"/docs/dl-pipeline"},{kind:"MdxPage",name:"feature-extraction",route:"/docs/feature-extraction"},{kind:"MdxPage",name:"limitations",route:"/docs/limitations"},{kind:"MdxPage",name:"performance",route:"/docs/performance"},{kind:"MdxPage",name:"pre-processing",route:"/docs/pre-processing"},{kind:"MdxPage",name:"problem-definition",route:"/docs/problem-definition"},{kind:"MdxPage",name:"references",route:"/docs/references"},{kind:"Folder",name:"scraping",route:"/docs/scraping",children:[{kind:"Meta",data:{"streaming-services":"Streaming Service APIs","data-quality":"Quality of data","store-data":"Store Data",transformation:"Transformation & Cleaning"}},{kind:"MdxPage",name:"data-quality",route:"/docs/scraping/data-quality"},{kind:"MdxPage",name:"store-data",route:"/docs/scraping/store-data"},{kind:"MdxPage",name:"streaming-services",route:"/docs/scraping/streaming-services"},{kind:"MdxPage",name:"transformation",route:"/docs/scraping/transformation"}]},{kind:"MdxPage",name:"scraping",route:"/docs/scraping"},{kind:"MdxPage",name:"sources",route:"/docs/sources"},{kind:"MdxPage",name:"technology-stack",route:"/docs/technology-stack"},{kind:"MdxPage",name:"training",route:"/docs/training"}]},{kind:"Folder",name:"experiments",route:"/experiments",children:[{kind:"Meta",data:{Experiments:{type:"separator",title:"Experiments"},archive:"Archive",binary:"Binary Classification"}},{kind:"MdxPage",name:"archive",route:"/experiments/archive"},{kind:"Folder",name:"binary",route:"/experiments/binary",children:[{kind:"Meta",data:{Training:{type:"separator",title:"Training"},"experiment-1":"Experiment 1","experiment-2":"Experiment 2","experiment-3":"Experiment 3","experiment-4":"Experiment 4","experiment-5":"Experiment 5"}},{kind:"MdxPage",name:"experiment-1",route:"/experiments/binary/experiment-1"},{kind:"MdxPage",name:"experiment-2",route:"/experiments/binary/experiment-2"},{kind:"MdxPage",name:"experiment-3",route:"/experiments/binary/experiment-3"},{kind:"MdxPage",name:"experiment-4",route:"/experiments/binary/experiment-4"},{kind:"MdxPage",name:"experiment-5",route:"/experiments/binary/experiment-5"}]},{kind:"MdxPage",name:"binary",route:"/experiments/binary"}]},{kind:"MdxPage",name:"index",route:"/"}],headings:[{depth:1,value:"Training",id:"training"},{depth:2,value:"Training Implementation",id:"training-implementation"},{depth:2,value:"Data Split",id:"data-split"}],timestamp:167870459e4,flexsearch:{codeblocks:!0},title:"Training"},nextraLayout:r.ZP,themeConfig:o.Z,Content:function(){let e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:{},{wrapper:t}=Object.assign({},(0,s.ah)(),e.components);return t?(0,i.jsx)(t,{...e,children:(0,i.jsx)(m,{...e})}):m(e)},hot:e.hot,pageOptsChecksum:"000000054a5b12c",dynamicMetaModules:[]})}},function(e){e.O(0,[774,32,888,179],function(){return e(e.s=4870)}),_N_E=e.O()}]);